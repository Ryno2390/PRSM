"""
PRSM S1 Neuro-Symbolic Orchestrator
==================================

This module implements the "Steering vs. Learning" architecture for PRSM.
It addresses the two core challenges:
1. Verification (Oracle Problem): Via Deterministic Sampling & Reasoning Traces.
2. Latency: Via Layered Inference (System 1/2) and Context Compression.

Features:
- Chronological Reasoning Trace for auditability.
- Reward Feedback loop for policy analysis.
- Proof of Useful Work via deterministic seed validation.
"""

import asyncio
import time
import logging
import random
import base64
import structlog
from uuid import uuid4
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timezone

import hashlib
from prsm.core.utils.deterministic import get_local_generator, generate_verification_hash
from prsm.core.cryptography.zk_proofs import get_zk_proof_system, ZKProofRequest
from prsm.compute.nwtn.engines.search_reasoning_engine import ReasoningNode
from prsm.core.cryptography.post_quantum import get_post_quantum_crypto, PostQuantumKeyPair
from prsm.compute.nwtn.reasoning.surprise_gating import SurpriseGater

logger = structlog.get_logger(__name__)

@dataclass
class ReasoningStep:
    """A single step in the reasoning trace"""
    timestamp: float
    action: str
    content: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    validation_hash: Optional[str] = None
    
    # Data Freshness & Provenance
    provenance_hash: Optional[str] = None
    data_version: str = "1.0.0"
    
    # Bayesian Surprise Gating
    surprise_score: float = 1.0

class ReasoningTrace:
    """A chronological record of the reasoning process for verification"""
    def __init__(self, trace_id: str, surprise_threshold: float = 0.0):
        self.trace_id = trace_id
        self.steps: List[ReasoningStep] = []
        self.start_time = time.time()
        self.surprise_threshold = surprise_threshold

    def add_step(self, action: str, content: str, metadata: Dict[str, Any] = None, provenance_hash: str = None, data_version: str = "1.0.0", surprise_score: float = 1.0):
        # SURPRISE GATING: Only preserve step if it exceeds threshold
        if surprise_score < self.surprise_threshold:
            logger.debug(f"ðŸ¤« Gating step '{action}': Low surprise ({surprise_score:.4f} < {self.surprise_threshold})")
            return False

        step = ReasoningStep(
            timestamp=time.time() - self.start_time,
            action=action,
            content=content,
            metadata=metadata or {},
            provenance_hash=provenance_hash,
            data_version=data_version,
            surprise_score=surprise_score
        )
        self.steps.append(step)
        return True

    def get_full_trace(self) -> List[Dict[str, Any]]:
        return [
            {
                "t": s.timestamp,
                "a": s.action,
                "c": s.content,
                "m": s.metadata,
                "p": s.provenance_hash,
                "v": s.data_version,
                "s": s.surprise_score
            } for s in self.steps
        ]

@dataclass
class StrategicPlan:
    """A research strategy generated by System 2"""
    task_id: str
    steps: List[Dict[str, Any]] # Each step has 'complexity' and 'target_system'
    total_estimated_cost: float

class StrategicResourceArbitrator:
    """
    FinOps for AI Agents.
    Routes tasks based on cost-efficiency using Plan-and-Execute pattern.
    """
    def __init__(self, node_id: str):
        self.node_id = node_id

    async def create_research_strategy(self, query: str) -> StrategicPlan:
        """System 2 creates the high-level plan (Expensive but smart)"""
        # In production, this calls a high-logic model
        return StrategicPlan(
            task_id=f"plan_{uuid4().hex[:6]}",
            steps=[
                {"a": "GENOMIC_ALIGNMENT", "complexity": "low"},
                {"a": "PROTEIN_FOLDING_SIM", "complexity": "high"},
                {"a": "DATA_NORMALIZATION", "complexity": "low"}
            ],
            total_estimated_cost=15.50
        )

    def route_step(self, step: Dict[str, Any]) -> str:
        """Decides which system (1 or 2) should handle the specific step"""
        if step["complexity"] == "high":
            return "system2"
        return "system1"

class NeuroSymbolicOrchestrator:
    """
    Orchestrates System 1 (Neural) and System 2 (Symbolic) reasoning.
    Implements verification and latency optimizations.
    """
    def __init__(self, node_id: str, seed: int = 42):
        self.node_id = node_id
        self.seed = seed
        self.rng = get_local_generator(seed)
        self.policy_weights: Dict[str, float] = {"exploration": 0.5, "consistency": 0.5}
        
        # FinOps Arbitrator
        self.arbitrator = StrategicResourceArbitrator(node_id)
        
        # Bayesian Surprise Gating
        self.gater = SurpriseGater(surprise_threshold=0.1)
        
        # PQC Infrastructure for Quantum-Resilient Provenance
        try:
            self.pq = get_post_quantum_crypto()
            self.pq_keypair = self.pq.generate_keypair()
        except Exception as e:
            logger.warning(f"PQC not available: {e}. Falling back to classical.")
            self.pq = None
            self.pq_keypair = None
        
    def calculate_royalty_multiplier(self, trace: List[Dict[str, Any]], latest_versions: Dict[str, str]) -> float:
        """
        Data Freshness Paradox: Penalize use of stale data blocks.
        """
        multiplier = 1.0
        for step in trace:
            prov_hash = step.get("p")
            if prov_hash and prov_hash in latest_versions:
                if step.get("v") != latest_versions[prov_hash]:
                    multiplier *= 0.5 # 50% penalty for stale data
        return multiplier

    async def solve_task(self, query: str, context: str) -> Dict[str, Any]:
        """
        Solves a task using layered inference and generates a verifiable trace.
        """
        trace = ReasoningTrace(
            trace_id=f"trace_{int(time.time())}", 
            surprise_threshold=self.gater.surprise_threshold
        )
        trace.add_step("INIT", f"Starting task for query: {query}", {"seed": self.seed})
        
        # FINOPS: Create research strategy
        strategy = await self.arbitrator.create_research_strategy(query)
        # Strategy planning is usually high surprise as it sets the stage
        trace.add_step(
            "STRATEGY_PLANNED", 
            f"Created plan {strategy.task_id}", 
            {"estimated_cost": strategy.total_estimated_cost},
            surprise_score=1.0 
        )

        # 1. LATENCY OPTIMIZATION: Layered Inference
        # System 1: Fast, intuitive proposal (System 1)
        s1_proposal = await self._system1_propose(query, context)
        
        # Calculate surprise relative to the initial query/context
        s1_surprise = self.gater.calculate_surprise(query, s1_proposal["content"])
        trace.add_step(
            "S1_PROPOSAL", 
            s1_proposal["content"], 
            {"latency": s1_proposal["latency"]},
            surprise_score=s1_surprise
        )
        
        # 2. VERIFICATION: Deterministic Sampling
        # Use a standardized task-specific salt for the decision
        task_salt = int(hashlib.sha256(query.encode()).hexdigest(), 16) % 10**8
        decision_rng = get_local_generator(self.seed + task_salt)
        
        verification_mode = "light"
        roll = decision_rng.next_float()
        if roll > 0.7: # 30% chance of deep verification
            verification_mode = "deep"
            
        trace.add_step("VERIFICATION_STRATEGY", f"Selected {verification_mode} mode", {"roll": roll})
        
        if verification_mode == "deep":
            # System 2: Deliberative search/verification
            s2_result = await self._system2_verify(s1_proposal["content"], query)
            # Deep verification is almost always high surprise
            trace.add_step(
                "S2_VERIFICATION", 
                s2_result["content"], 
                {"reward": s2_result["reward"]},
                surprise_score=0.9
            )
            final_content = s2_result["content"]
            reward = s2_result["reward"]
        else:
            # Light Symbolic Check
            final_content = s1_proposal["content"]
            reward = 0.5 # Default reward for light check
            # Light check surprise depends on how much it changes our confidence
            trace.add_step("S2_LIGHT_CHECK", "Passed basic symbolic constraints", surprise_score=0.2)

        # 3. GENERATE PROOF OF USEFUL WORK
        # Generate a hash of the trace using the deterministic quantization
        input_hash = hashlib.sha256((query + context).encode()).hexdigest()
        v_hash = generate_verification_hash(
            output_data=final_content,
            model_id="nwtn_v1",
            input_hash=input_hash
        )
        
        # QUANTUM RESILIENCE: Sign the hash with PQC
        pq_signature = None
        if self.pq and self.pq_keypair:
            pq_sig_obj = self.pq.sign_message(v_hash, self.pq_keypair)
            pq_signature = pq_sig_obj.to_dict()

        # 4. REWARD FEEDBACK LOOP
        self._update_policy(reward)
        
        return {
            "node_id": self.node_id,
            "output": final_content,
            "input_hash": input_hash,
            "verification_hash": v_hash,
            "pq_signature": pq_signature,
            "trace": trace.get_full_trace(),
            "reward": reward,
            "mode": verification_mode,
            "metadata": {
                "query": query,
                "mode": verification_mode,
                "seed": self.seed,
                "worker_pk": base64.b64encode(self.pq_keypair.public_key).decode() if self.pq_keypair else None
            }
        }

    async def _system1_propose(self, query: str, context: str) -> Dict[str, Any]:
        """Fast inference layer (System 1)"""
        start = time.time()
        # Simulated fast SSM inference
        await asyncio.sleep(0.1) 
        return {
            "content": f"Neural intuition for {query[:20]}...",
            "latency": time.time() - start
        }

    async def _system2_verify(self, proposal: str, query: str) -> Dict[str, Any]:
        """Deliberative verification layer (System 2)"""
        # Here we would invoke the SearchReasoningEngine or MCTS
        from prsm.compute.nwtn.engines.search_reasoning_engine import SearchReasoningEngine
        
        # Mocking MCTS call for the prototype
        await asyncio.sleep(0.3)
        reward = self.rng.next_float() * 0.5 + 0.5 # 0.5 to 1.0
        
        return {
            "content": f"Verified breakthrough: {proposal} is scientifically sound.",
            "reward": reward
        }

    def _update_policy(self, reward: float):
        """Reward Feedback loop to update internal weights"""
        learning_rate = 0.1
        if reward > 0.8:
            self.policy_weights["consistency"] += learning_rate
        else:
            self.policy_weights["exploration"] += learning_rate
        
        # Normalize
        total = sum(self.policy_weights.values())
        for k in self.policy_weights:
            self.policy_weights[k] /= total

    async def verify_remote_node(self, task_data: Dict[str, Any], seed: int, shard_index: int = 0, total_shards: int = 1) -> bool:
        """
        Allows a validator node to verify if a worker node actually did the work.
        Crucial for solving the Oracle Problem.
        
        Supports Sharded Verification: verify only a subset of the logic chain.
        """
        # 1. ORACLE VERIFICATION: Partial Re-execution
        query = task_data.get("metadata", {}).get("query", "")
        task_salt = int(hashlib.sha256(query.encode()).hexdigest(), 16) % 10**8
        decision_rng = get_local_generator(seed + task_salt)
        
        v_mode = "light"
        roll = decision_rng.next_float()
        if roll > 0.7:
            v_mode = "deep"
            
        reported_mode = task_data.get("metadata", {}).get("mode")
        if reported_mode != v_mode:
            return False

        # 2. SHARDED TRACE VERIFICATION
        # Instead of verifying 100% of the steps, we verify a shard
        trace = task_data.get("trace", [])
        if not trace:
            return False
            
        shard_size = max(1, len(trace) // total_shards)
        start_idx = shard_index * shard_size
        end_idx = min(start_idx + shard_size, len(trace))
        
        for i in range(start_idx, end_idx):
            step = trace[i]
            # Verify internal consistency of the step hash
            # (In production, we'd re-run the specific MCTS branch here)
            if step.get("p"):
                # ZKP Data Access: Prove dataset usage without raw data exposure
                # We verify the ZKP provided by the worker for this provenance hash
                zkp_valid = await self._verify_data_zkp(step["p"], step.get("zkp_proof"))
                if not zkp_valid:
                    logger.error(f"ZKP Verification Failed for dataset: {step['p']}")
                    return False

        # 3. Deterministic Hash consistency
        input_hash = task_data.get("input_hash", "none")
        local_v_hash = generate_verification_hash(
            output_data=task_data["output"],
            model_id="nwtn_v1",
            input_hash=input_hash
        )
        
        hash_match = (local_v_hash == task_data["verification_hash"])
        
        # QUANTUM RESILIENCE: Verify PQC signature if available
        pq_valid = True
        pq_sig_data = task_data.get("pq_signature")
        if pq_sig_data and self.pq:
            from prsm.core.cryptography.post_quantum import PostQuantumSignature
            pq_sig = PostQuantumSignature.from_dict(pq_sig_data)
            # In a real scenario, we'd fetch the worker's public key from the on-chain registry/NHI
            worker_pk = task_data.get("metadata", {}).get("worker_pk")
            if worker_pk:
                pq_valid = self.pq.verify_signature(local_v_hash, pq_sig, base64.b64decode(worker_pk))

        return hash_match and pq_valid and (task_data.get("reward", 0.0) > 0.0)

    async def _verify_data_zkp(self, provenance_hash: str, proof: Any) -> bool:
        """
        Secures royalties without exposing raw data.
        In a real implementation, this would use the ZKProofSystem to verify 
        that the node processed the block matching the provenance hash.
        """
        # Placeholder for real ZK verification
        if proof == "invalid_proof":
            return False
        return True
