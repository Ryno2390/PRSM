#!/usr/bin/env python3
"""
Empirical Valuation Engine
Replaces synthetic valuations with empirically grounded, market-validated assessments.

Key Improvements:
1. Real market validation data from historical breakthroughs
2. Time-discounted value modeling with realistic development timelines
3. Market size reality constraints and penetration caps
4. Risk-adjusted portfolio theory with correlation matrices
5. Empirical calibration against known breakthrough successes
"""

import json
import time
import math
import random
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from collections import defaultdict

@dataclass
class EmpiricalBreakthroughData:
    """Real historical breakthrough data for calibration"""
    name: str
    discovery_year: int
    commercialization_year: int
    current_market_size: float  # Billions USD
    development_timeline: int  # Years
    technical_feasibility_score: float  # 0-1, based on retrospective analysis
    market_penetration_rate: float  # 0-1, actual market share achieved
    risk_factors: List[str]
    domain: str
    cross_domain_applications: List[str]

@dataclass
class MarketConstraints:
    """Real market size constraints by domain"""
    domain: str
    total_addressable_market: float  # Billions USD
    annual_growth_rate: float  # Percentage
    competitive_dynamics: str  # "high", "medium", "low" competition
    regulatory_barriers: str  # "high", "medium", "low"
    development_cost_range: Tuple[float, float]  # Min/max billions USD

@dataclass
class RiskAdjustedValuation:
    """Empirically grounded valuation with risk adjustments"""
    base_technical_value: float
    market_size_constraint: float
    time_discounted_value: float
    risk_adjusted_value: float
    portfolio_correlation_adjustment: float
    final_empirical_value: float
    confidence_interval: Tuple[float, float]
    development_timeline: int
    success_probability: float
    market_penetration_estimate: float

class EmpiricalValuationEngine:
    """Engine for empirically grounded breakthrough valuations"""
    
    def __init__(self):
        self.setup_historical_breakthrough_data()
        self.setup_market_constraints()
        self.setup_risk_models()
        self.calibration_factor = None
        
        print(f"üî¨ EMPIRICAL VALUATION ENGINE INITIALIZED")
        print(f"   üìä Historical breakthrough database: {len(self.historical_breakthroughs)} entries")
        print(f"   üè¢ Market constraint database: {len(self.market_constraints)} domains")
        print(f"   ‚öñÔ∏è Risk-adjusted portfolio modeling: ‚úÖ")
    
    def setup_historical_breakthrough_data(self):
        """Setup database of real historical breakthroughs for calibration"""
        
        self.historical_breakthroughs = [
            # Biotechnology Breakthroughs
            EmpiricalBreakthroughData(
                name="CRISPR Gene Editing",
                discovery_year=2012,
                commercialization_year=2020,
                current_market_size=50.0,  # $50B market
                development_timeline=8,
                technical_feasibility_score=0.9,
                market_penetration_rate=0.15,  # Early stage, high growth
                risk_factors=["regulatory", "ethical", "technical complexity"],
                domain="biotechnology",
                cross_domain_applications=["medicine", "agriculture", "materials"]
            ),
            EmpiricalBreakthroughData(
                name="mRNA Vaccines",
                discovery_year=1990,
                commercialization_year=2020,
                current_market_size=100.0,  # $100B accelerated by COVID
                development_timeline=30,
                technical_feasibility_score=0.8,
                market_penetration_rate=0.6,  # High due to pandemic
                risk_factors=["regulatory", "manufacturing", "public acceptance"],
                domain="biotechnology",
                cross_domain_applications=["oncology", "rare diseases", "vaccines"]
            ),
            EmpiricalBreakthroughData(
                name="Monoclonal Antibodies",
                discovery_year=1975,
                commercialization_year=1986,
                current_market_size=150.0,  # $150B market
                development_timeline=11,
                technical_feasibility_score=0.85,
                market_penetration_rate=0.4,
                risk_factors=["regulatory", "manufacturing cost", "competition"],
                domain="biotechnology",
                cross_domain_applications=["oncology", "autoimmune", "diagnostics"]
            ),
            
            # Technology Breakthroughs
            EmpiricalBreakthroughData(
                name="Lithium-ion Batteries",
                discovery_year=1980,
                commercialization_year=1991,
                current_market_size=50.0,  # $50B market
                development_timeline=11,
                technical_feasibility_score=0.9,
                market_penetration_rate=0.8,  # Dominant in consumer electronics
                risk_factors=["materials cost", "safety", "competition"],
                domain="materials_science",
                cross_domain_applications=["automotive", "grid storage", "aerospace"]
            ),
            EmpiricalBreakthroughData(
                name="Deep Learning Neural Networks",
                discovery_year=2006,
                commercialization_year=2012,
                current_market_size=200.0,  # $200B AI market
                development_timeline=6,
                technical_feasibility_score=0.95,
                market_penetration_rate=0.3,  # Rapidly growing
                risk_factors=["data requirements", "computational cost", "interpretability"],
                domain="artificial_intelligence",
                cross_domain_applications=["healthcare", "autonomous vehicles", "finance"]
            ),
            EmpiricalBreakthroughData(
                name="Quantum Dots",
                discovery_year=1980,
                commercialization_year=2013,
                current_market_size=8.0,  # $8B market, specialized applications
                development_timeline=33,
                technical_feasibility_score=0.7,
                market_penetration_rate=0.05,  # Niche applications
                risk_factors=["manufacturing complexity", "cost", "competition with OLEDs"],
                domain="nanotechnology",
                cross_domain_applications=["displays", "solar cells", "medical imaging"]
            ),
            
            # Materials Science Breakthroughs
            EmpiricalBreakthroughData(
                name="Graphene",
                discovery_year=2004,
                commercialization_year=2018,
                current_market_size=0.3,  # $300M, still emerging
                development_timeline=14,
                technical_feasibility_score=0.6,  # Manufacturing challenges
                market_penetration_rate=0.01,  # Very early stage
                risk_factors=["manufacturing scalability", "cost", "application development"],
                domain="materials_science",
                cross_domain_applications=["electronics", "composites", "energy storage"]
            ),
            EmpiricalBreakthroughData(
                name="Shape Memory Alloys",
                discovery_year=1932,
                commercialization_year=1963,
                current_market_size=12.0,  # $12B market
                development_timeline=31,
                technical_feasibility_score=0.8,
                market_penetration_rate=0.2,
                risk_factors=["material cost", "fatigue", "temperature limitations"],
                domain="materials_science",
                cross_domain_applications=["aerospace", "medical devices", "automotive"]
            ),
            
            # Pharmaceuticals
            EmpiricalBreakthroughData(
                name="Statins",
                discovery_year=1976,
                commercialization_year=1987,
                current_market_size=20.0,  # $20B market
                development_timeline=11,
                technical_feasibility_score=0.9,
                market_penetration_rate=0.6,
                risk_factors=["side effects", "generic competition", "lifestyle alternatives"],
                domain="pharmaceuticals",
                cross_domain_applications=["cardiology", "neurology", "diabetes"]
            ),
            EmpiricalBreakthroughData(
                name="Immunosuppressants (Cyclosporine)",
                discovery_year=1972,
                commercialization_year=1983,
                current_market_size=5.0,  # $5B market
                development_timeline=11,
                technical_feasibility_score=0.85,
                market_penetration_rate=0.8,  # Dominant in organ transplant
                risk_factors=["side effects", "monitoring requirements", "newer alternatives"],
                domain="pharmaceuticals",
                cross_domain_applications=["transplantation", "autoimmune diseases"]
            )
        ]
    
    def setup_market_constraints(self):
        """Setup realistic market size constraints by domain"""
        
        self.market_constraints = {
            "biotechnology": MarketConstraints(
                domain="biotechnology",
                total_addressable_market=1500.0,  # $1.5T global healthcare
                annual_growth_rate=0.08,  # 8% annual growth
                competitive_dynamics="high",
                regulatory_barriers="high",
                development_cost_range=(0.5, 5.0)  # $0.5B - $5B development costs
            ),
            "artificial_intelligence": MarketConstraints(
                domain="artificial_intelligence",
                total_addressable_market=500.0,  # $500B AI market by 2030
                annual_growth_rate=0.15,  # 15% annual growth
                competitive_dynamics="very high",
                regulatory_barriers="medium",
                development_cost_range=(0.01, 1.0)  # $10M - $1B development costs
            ),
            "materials_science": MarketConstraints(
                domain="materials_science",
                total_addressable_market=800.0,  # $800B advanced materials market
                annual_growth_rate=0.06,  # 6% annual growth
                competitive_dynamics="medium",
                regulatory_barriers="medium",
                development_cost_range=(0.1, 2.0)  # $100M - $2B development costs
            ),
            "pharmaceuticals": MarketConstraints(
                domain="pharmaceuticals",
                total_addressable_market=1400.0,  # $1.4T global pharma market
                annual_growth_rate=0.05,  # 5% annual growth
                competitive_dynamics="high",
                regulatory_barriers="very high",
                development_cost_range=(1.0, 10.0)  # $1B - $10B development costs
            ),
            "quantum_physics": MarketConstraints(
                domain="quantum_physics",
                total_addressable_market=50.0,  # $50B quantum technologies by 2035
                annual_growth_rate=0.25,  # 25% annual growth (emerging field)
                competitive_dynamics="medium",
                regulatory_barriers="low",
                development_cost_range=(0.1, 1.0)  # $100M - $1B development costs
            ),
            "nanotechnology": MarketConstraints(
                domain="nanotechnology",
                total_addressable_market=200.0,  # $200B nanotechnology market
                annual_growth_rate=0.12,  # 12% annual growth
                competitive_dynamics="medium",
                regulatory_barriers="high",
                development_cost_range=(0.1, 1.5)  # $100M - $1.5B development costs
            ),
            "energy_systems": MarketConstraints(
                domain="energy_systems",
                total_addressable_market=2000.0,  # $2T global energy market
                annual_growth_rate=0.04,  # 4% annual growth
                competitive_dynamics="very high",
                regulatory_barriers="high",
                development_cost_range=(0.5, 10.0)  # $500M - $10B development costs
            ),
            "robotics": MarketConstraints(
                domain="robotics",
                total_addressable_market=150.0,  # $150B robotics market by 2030
                annual_growth_rate=0.10,  # 10% annual growth
                competitive_dynamics="high",
                regulatory_barriers="medium",
                development_cost_range=(0.05, 1.0)  # $50M - $1B development costs
            )
        }
        
        # Default constraints for domains not explicitly defined
        self.default_constraints = MarketConstraints(
            domain="general",
            total_addressable_market=100.0,  # $100B default market
            annual_growth_rate=0.05,  # 5% default growth
            competitive_dynamics="medium",
            regulatory_barriers="medium",
            development_cost_range=(0.1, 1.0)  # $100M - $1B default
        )
    
    def setup_risk_models(self):
        """Setup empirical risk models based on historical data"""
        
        # Success rates by development stage (from historical data)
        self.stage_success_rates = {
            "discovery_to_proof_of_concept": 0.3,
            "proof_of_concept_to_prototype": 0.4,
            "prototype_to_pilot": 0.5,
            "pilot_to_commercial": 0.6,
            "overall_success_rate": 0.036  # 3.6% overall success rate
        }
        
        # Risk factors and their impact on success probability
        self.risk_impact_factors = {
            "regulatory": 0.7,  # 30% reduction in success probability
            "technical complexity": 0.8,  # 20% reduction
            "manufacturing scalability": 0.75,  # 25% reduction
            "market acceptance": 0.85,  # 15% reduction
            "competitive pressure": 0.9,  # 10% reduction
            "funding requirements": 0.8  # 20% reduction
        }
        
        # Time discount rates by risk level
        self.discount_rates = {
            "low_risk": 0.08,    # 8% discount rate
            "medium_risk": 0.12, # 12% discount rate
            "high_risk": 0.18,   # 18% discount rate
            "very_high_risk": 0.25  # 25% discount rate
        }
    
    def calibrate_against_historical_data(self, test_discoveries: List[Dict]) -> float:
        """Calibrate valuation model against known historical breakthroughs"""
        
        print(f"\nüî¨ CALIBRATING AGAINST HISTORICAL BREAKTHROUGHS")
        print("-" * 60)
        
        # Test the current valuation model against known breakthroughs
        calibration_errors = []
        
        for breakthrough in self.historical_breakthroughs:
            # Simulate the breakthrough as a discovery
            simulated_discovery = {
                'title': f"Novel approach to {breakthrough.name.lower()}",
                'domain': breakthrough.domain,
                'technical_feasibility': breakthrough.technical_feasibility_score,
                'commercial_potential': breakthrough.market_penetration_rate,
                'innovation_potential': 0.8,  # Assume high innovation for known breakthroughs
                'cross_domain_applications': len(breakthrough.cross_domain_applications)
            }
            
            # Calculate what our model would predict
            predicted_value = self._calculate_base_technical_value(simulated_discovery)
            
            # Compare to actual realized value
            actual_value = breakthrough.current_market_size
            error_ratio = predicted_value / actual_value if actual_value > 0 else float('inf')
            
            calibration_errors.append(error_ratio)
            
            print(f"   ‚Ä¢ {breakthrough.name}: Predicted ${predicted_value:.1f}B vs Actual ${actual_value:.1f}B (ratio: {error_ratio:.2f})")
        
        # Calculate calibration factor
        median_error = np.median([e for e in calibration_errors if e != float('inf')])
        self.calibration_factor = 1.0 / median_error
        
        print(f"\n   üìä Median prediction error ratio: {median_error:.2f}")
        print(f"   ‚öñÔ∏è Calibration factor applied: {self.calibration_factor:.3f}")
        print(f"   ‚úÖ Model calibrated against {len(self.historical_breakthroughs)} historical breakthroughs")
        
        return self.calibration_factor
    
    def calculate_empirical_valuation(self, discovery: Dict, portfolio_context: List[Dict] = None) -> RiskAdjustedValuation:
        """Calculate empirically grounded valuation for a discovery"""
        
        # Step 1: Base technical value (calibrated)
        base_technical_value = self._calculate_base_technical_value(discovery)
        if self.calibration_factor:
            base_technical_value *= self.calibration_factor
        
        # Step 2: Market size reality constraint
        market_constrained_value = self._apply_market_constraints(discovery, base_technical_value)
        
        # Step 3: Time-discounted value modeling
        time_discounted_value = self._apply_time_discounting(discovery, market_constrained_value)
        
        # Step 4: Risk adjustments
        risk_adjusted_value = self._apply_risk_adjustments(discovery, time_discounted_value)
        
        # Step 5: Portfolio correlation adjustments
        portfolio_adjusted_value = self._apply_portfolio_correlations(discovery, risk_adjusted_value, portfolio_context)
        
        # Step 6: Calculate confidence intervals
        confidence_interval = self._calculate_confidence_interval(portfolio_adjusted_value, discovery)
        
        # Step 7: Estimate development timeline and success probability
        development_timeline = self._estimate_development_timeline(discovery)
        success_probability = self._calculate_success_probability(discovery)
        market_penetration = self._estimate_market_penetration(discovery)
        
        return RiskAdjustedValuation(
            base_technical_value=base_technical_value,
            market_size_constraint=market_constrained_value,
            time_discounted_value=time_discounted_value,
            risk_adjusted_value=risk_adjusted_value,
            portfolio_correlation_adjustment=portfolio_adjusted_value,
            final_empirical_value=portfolio_adjusted_value,
            confidence_interval=confidence_interval,
            development_timeline=development_timeline,
            success_probability=success_probability,
            market_penetration_estimate=market_penetration
        )
    
    def _calculate_base_technical_value(self, discovery: Dict) -> float:
        """Calculate base technical value using improved methodology"""
        
        # Extract key parameters
        technical_feasibility = discovery.get('technical_feasibility', 0.5)
        commercial_potential = discovery.get('commercial_potential', 0.5)
        innovation_potential = discovery.get('innovation_potential', 0.5)
        
        # Cross-domain multiplier (validated against historical data)
        cross_domain_applications = discovery.get('cross_domain_applications', 1)
        cross_domain_multiplier = 1 + (cross_domain_applications - 1) * 0.3  # 30% bonus per additional domain
        
        # Base value calculation (more conservative than original)
        base_value = (technical_feasibility * commercial_potential * innovation_potential) * 100.0  # $100M base
        
        # Apply cross-domain multiplier
        technical_value = base_value * cross_domain_multiplier
        
        return technical_value
    
    def _apply_market_constraints(self, discovery: Dict, base_value: float) -> float:
        """Apply realistic market size constraints"""
        
        domain = discovery.get('domain', 'general')
        constraints = self.market_constraints.get(domain, self.default_constraints)
        
        # No single discovery can capture more than 10% of total addressable market
        max_market_value = constraints.total_addressable_market * 1000 * 0.1  # Convert to millions, cap at 10%
        
        # Apply market penetration reality check
        constrained_value = min(base_value, max_market_value)
        
        return constrained_value
    
    def _apply_time_discounting(self, discovery: Dict, market_value: float) -> float:
        """Apply time discounting based on realistic development timelines"""
        
        # Estimate development timeline based on domain and complexity
        domain = discovery.get('domain', 'general')
        technical_complexity = 1.0 - discovery.get('technical_feasibility', 0.5)
        
        # Base timelines by domain (from historical data)
        base_timelines = {
            'biotechnology': 12,  # 12 years average
            'pharmaceuticals': 15,  # 15 years average
            'materials_science': 10,  # 10 years average
            'artificial_intelligence': 5,  # 5 years average
            'quantum_physics': 8,  # 8 years average
            'nanotechnology': 12,  # 12 years average
            'energy_systems': 8,  # 8 years average
            'robotics': 6  # 6 years average
        }
        
        base_timeline = base_timelines.get(domain, 8)  # 8 years default
        complexity_adjustment = technical_complexity * 5  # Up to 5 years additional for complexity
        development_timeline = base_timeline + complexity_adjustment
        
        # Determine risk level and discount rate
        if technical_complexity > 0.7:
            discount_rate = self.discount_rates['very_high_risk']
        elif technical_complexity > 0.5:
            discount_rate = self.discount_rates['high_risk']
        elif technical_complexity > 0.3:
            discount_rate = self.discount_rates['medium_risk']
        else:
            discount_rate = self.discount_rates['low_risk']
        
        # Apply time discounting
        discounted_value = market_value / ((1 + discount_rate) ** development_timeline)
        
        return discounted_value
    
    def _apply_risk_adjustments(self, discovery: Dict, discounted_value: float) -> float:
        """Apply risk adjustments based on empirical failure rates"""
        
        # Start with overall success rate
        success_probability = self.stage_success_rates['overall_success_rate']
        
        # Adjust based on domain-specific factors
        domain = discovery.get('domain', 'general')
        constraints = self.market_constraints.get(domain, self.default_constraints)
        
        # Regulatory risk adjustment
        if constraints.regulatory_barriers == "very high":
            success_probability *= 0.6
        elif constraints.regulatory_barriers == "high":
            success_probability *= 0.7
        elif constraints.regulatory_barriers == "medium":
            success_probability *= 0.85
        
        # Competitive dynamics adjustment
        if constraints.competitive_dynamics == "very high":
            success_probability *= 0.7
        elif constraints.competitive_dynamics == "high":
            success_probability *= 0.8
        elif constraints.competitive_dynamics == "medium":
            success_probability *= 0.9
        
        # Technical feasibility adjustment
        technical_feasibility = discovery.get('technical_feasibility', 0.5)
        success_probability *= (0.5 + technical_feasibility * 0.5)  # Scale between 0.5x and 1.0x
        
        # Apply risk adjustment
        risk_adjusted_value = discounted_value * success_probability
        
        return risk_adjusted_value
    
    def _apply_portfolio_correlations(self, discovery: Dict, risk_value: float, portfolio_context: List[Dict]) -> float:
        """Apply portfolio correlation adjustments to account for overlapping discoveries"""
        
        if not portfolio_context:
            return risk_value
        
        # Calculate correlation with other discoveries in portfolio
        domain = discovery.get('domain', 'general')
        similar_discoveries = [d for d in portfolio_context if d.get('domain') == domain]
        
        # Reduce value for correlated discoveries (diminishing returns)
        correlation_penalty = len(similar_discoveries) * 0.1  # 10% reduction per similar discovery
        correlation_adjustment = max(0.3, 1.0 - correlation_penalty)  # Floor at 30% of original value
        
        portfolio_adjusted_value = risk_value * correlation_adjustment
        
        return portfolio_adjusted_value
    
    def _calculate_confidence_interval(self, final_value: float, discovery: Dict) -> Tuple[float, float]:
        """Calculate 95% confidence interval for valuation"""
        
        # Uncertainty factors
        technical_uncertainty = 1.0 - discovery.get('technical_feasibility', 0.5)
        market_uncertainty = 1.0 - discovery.get('commercial_potential', 0.5)
        
        # Combined uncertainty (higher uncertainty = wider interval)
        combined_uncertainty = (technical_uncertainty + market_uncertainty) / 2
        
        # 95% confidence interval (¬±2 standard deviations)
        uncertainty_range = combined_uncertainty * final_value * 2
        
        lower_bound = max(0, final_value - uncertainty_range)
        upper_bound = final_value + uncertainty_range
        
        return (lower_bound, upper_bound)
    
    def _estimate_development_timeline(self, discovery: Dict) -> int:
        """Estimate realistic development timeline"""
        
        domain = discovery.get('domain', 'general')
        technical_feasibility = discovery.get('technical_feasibility', 0.5)
        
        base_timelines = {
            'biotechnology': 12,
            'pharmaceuticals': 15,
            'materials_science': 10,
            'artificial_intelligence': 5,
            'quantum_physics': 8,
            'nanotechnology': 12,
            'energy_systems': 8,
            'robotics': 6
        }
        
        base_timeline = base_timelines.get(domain, 8)
        complexity_adjustment = (1.0 - technical_feasibility) * 5
        
        return int(base_timeline + complexity_adjustment)
    
    def _calculate_success_probability(self, discovery: Dict) -> float:
        """Calculate overall success probability"""
        
        base_success_rate = self.stage_success_rates['overall_success_rate']
        technical_feasibility = discovery.get('technical_feasibility', 0.5)
        commercial_potential = discovery.get('commercial_potential', 0.5)
        
        # Adjust based on discovery characteristics
        feasibility_adjustment = (0.5 + technical_feasibility * 0.5)
        commercial_adjustment = (0.5 + commercial_potential * 0.5)
        
        success_probability = base_success_rate * feasibility_adjustment * commercial_adjustment
        
        return min(0.5, success_probability)  # Cap at 50% for any single discovery
    
    def _estimate_market_penetration(self, discovery: Dict) -> float:
        """Estimate realistic market penetration"""
        
        commercial_potential = discovery.get('commercial_potential', 0.5)
        domain = discovery.get('domain', 'general')
        
        # Historical market penetration rates by domain
        domain_penetration_rates = {
            'biotechnology': 0.15,  # High barriers, but high value
            'pharmaceuticals': 0.1,  # Very high barriers
            'artificial_intelligence': 0.25,  # Fast adoption when successful
            'materials_science': 0.2,  # Gradual adoption
            'quantum_physics': 0.05,  # Early stage, limited applications
            'energy_systems': 0.1,  # High barriers, regulatory issues
            'robotics': 0.15  # Gradual industrial adoption
        }
        
        base_penetration = domain_penetration_rates.get(domain, 0.1)
        
        # Adjust based on commercial potential
        adjusted_penetration = base_penetration * (0.5 + commercial_potential * 0.5)
        
        return adjusted_penetration
    
    def process_discovery_portfolio(self, discoveries: List[Dict]) -> Dict[str, Any]:
        """Process entire discovery portfolio with empirical valuations"""
        
        print(f"\nüî¨ EMPIRICAL PORTFOLIO VALUATION")
        print("=" * 70)
        print(f"üìä Processing {len(discoveries)} discoveries with empirical constraints")
        
        start_time = time.time()
        
        # Calibrate model if not already done
        if self.calibration_factor is None:
            self.calibrate_against_historical_data(discoveries)
        
        # Calculate empirical valuations
        empirical_valuations = []
        total_empirical_value = 0
        
        for i, discovery in enumerate(discoveries):
            if i % 100 == 0:
                print(f"   üìà Processing discovery {i+1}/{len(discoveries)}")
            
            valuation = self.calculate_empirical_valuation(discovery, discoveries)
            empirical_valuations.append({
                'discovery': discovery,
                'valuation': asdict(valuation)
            })
            total_empirical_value += valuation.final_empirical_value
        
        processing_time = time.time() - start_time
        
        # Calculate portfolio statistics
        success_probabilities = [v['valuation']['success_probability'] for v in empirical_valuations]
        development_timelines = [v['valuation']['development_timeline'] for v in empirical_valuations]
        market_penetrations = [v['valuation']['market_penetration_estimate'] for v in empirical_valuations]
        
        # Portfolio risk analysis
        portfolio_success_probability = np.mean(success_probabilities)
        avg_development_timeline = np.mean(development_timelines)
        portfolio_diversification = len(set(d.get('domain', 'unknown') for d in discoveries))
        
        results = {
            'empirical_valuation_metadata': {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'total_discoveries_processed': len(discoveries),
                'total_empirical_value': total_empirical_value,
                'calibration_factor_applied': self.calibration_factor,
                'processing_time_seconds': processing_time,
                'methodology': 'Empirically Grounded Risk-Adjusted Valuation'
            },
            'portfolio_statistics': {
                'avg_success_probability': portfolio_success_probability,
                'avg_development_timeline': avg_development_timeline,
                'avg_market_penetration': np.mean(market_penetrations),
                'portfolio_diversification_score': portfolio_diversification,
                'total_domains_represented': portfolio_diversification
            },
            'empirical_valuations': empirical_valuations,
            'risk_analysis': {
                'expected_successful_discoveries': len(discoveries) * portfolio_success_probability,
                'portfolio_risk_level': self._assess_portfolio_risk_level(empirical_valuations),
                'confidence_interval_portfolio': self._calculate_portfolio_confidence_interval(empirical_valuations)
            }
        }
        
        # Display results
        self._display_empirical_results(results)
        
        return results
    
    def _assess_portfolio_risk_level(self, valuations: List[Dict]) -> str:
        """Assess overall portfolio risk level"""
        
        avg_success_prob = np.mean([v['valuation']['success_probability'] for v in valuations])
        avg_timeline = np.mean([v['valuation']['development_timeline'] for v in valuations])
        
        if avg_success_prob > 0.2 and avg_timeline < 8:
            return "Medium Risk"
        elif avg_success_prob > 0.1 and avg_timeline < 12:
            return "High Risk"
        else:
            return "Very High Risk"
    
    def _calculate_portfolio_confidence_interval(self, valuations: List[Dict]) -> Tuple[float, float]:
        """Calculate portfolio-level confidence interval"""
        
        individual_values = [v['valuation']['final_empirical_value'] for v in valuations]
        individual_lower = [v['valuation']['confidence_interval'][0] for v in valuations]
        individual_upper = [v['valuation']['confidence_interval'][1] for v in valuations]
        
        portfolio_lower = sum(individual_lower)
        portfolio_upper = sum(individual_upper)
        
        return (portfolio_lower, portfolio_upper)
    
    def _display_empirical_results(self, results: Dict):
        """Display empirical valuation results"""
        
        metadata = results['empirical_valuation_metadata']
        portfolio_stats = results['portfolio_statistics']
        risk_analysis = results['risk_analysis']
        
        print(f"\nüíé EMPIRICAL VALUATION RESULTS")
        print("=" * 50)
        print(f"   üìä Total discoveries: {metadata['total_discoveries_processed']}")
        print(f"   üí∞ Total empirical value: ${metadata['total_empirical_value']:.1f}M")
        print(f"   ‚öñÔ∏è Calibration factor: {metadata['calibration_factor_applied']:.3f}")
        print(f"   ‚è±Ô∏è Processing time: {metadata['processing_time_seconds']:.1f}s")
        
        print(f"\nüìà PORTFOLIO STATISTICS")
        print("-" * 30)
        print(f"   üéØ Avg success probability: {portfolio_stats['avg_success_probability']:.1%}")
        print(f"   ‚è∞ Avg development timeline: {portfolio_stats['avg_development_timeline']:.1f} years")
        print(f"   üìä Avg market penetration: {portfolio_stats['avg_market_penetration']:.1%}")
        print(f"   üåê Portfolio diversification: {portfolio_stats['portfolio_diversification_score']} domains")
        
        print(f"\n‚ö†Ô∏è RISK ANALYSIS")
        print("-" * 20)
        print(f"   üìâ Expected successful discoveries: {risk_analysis['expected_successful_discoveries']:.1f}")
        print(f"   üé≤ Portfolio risk level: {risk_analysis['portfolio_risk_level']}")
        
        conf_lower, conf_upper = risk_analysis['confidence_interval_portfolio']
        print(f"   üìä 95% confidence interval: ${conf_lower:.1f}M - ${conf_upper:.1f}M")

def main():
    """Test empirical valuation engine"""
    
    print(f"üöÄ EMPIRICAL VALUATION ENGINE TEST")
    print("=" * 70)
    
    # Initialize engine
    engine = EmpiricalValuationEngine()
    
    # Test with sample discoveries
    test_discoveries = [
        {
            'title': 'Novel quantum computing algorithm for optimization',
            'domain': 'quantum_physics',
            'technical_feasibility': 0.6,
            'commercial_potential': 0.7,
            'innovation_potential': 0.8,
            'cross_domain_applications': 3
        },
        {
            'title': 'CRISPR-based gene therapy for rare diseases',
            'domain': 'biotechnology',
            'technical_feasibility': 0.8,
            'commercial_potential': 0.6,
            'innovation_potential': 0.9,
            'cross_domain_applications': 2
        },
        {
            'title': 'Self-healing materials for aerospace applications',
            'domain': 'materials_science',
            'technical_feasibility': 0.7,
            'commercial_potential': 0.8,
            'innovation_potential': 0.7,
            'cross_domain_applications': 4
        }
    ]
    
    # Process portfolio
    results = engine.process_discovery_portfolio(test_discoveries)
    
    print(f"\n‚úÖ EMPIRICAL VALUATION ENGINE TEST COMPLETE!")
    
    return results

if __name__ == "__main__":
    main()