#!/usr/bin/env python3
"""
Agent Framework Integration Testing
Test the complete 5-layer agent system with NWTN orchestrator
Phase 1 / Week 4 - Agent Foundation Layer Testing
"""

import pytest
pytest.skip('Module dependencies not yet fully implemented', allow_module_level=True)

import asyncio
import sys
from typing import Dict, Any
from uuid import UUID, uuid4

# Structured logging
import structlog
structlog.configure(
    processors=[
        structlog.dev.ConsoleRenderer(colors=True)
    ],
    wrapper_class=structlog.make_filtering_bound_logger(20),
    logger_factory=structlog.PrintLoggerFactory(),
    cache_logger_on_first_use=True,
)
logger = structlog.get_logger(__name__)

# PRSM imports
from prsm.core.models import UserInput, AgentType
from prsm.compute.agents.base import BaseAgent, AgentPool, agent_registry
from prsm.compute.agents.architects.hierarchical_architect import HierarchicalArchitect
from prsm.compute.agents.routers.model_router import ModelRouter
from prsm.compute.agents.executors.model_executor import ModelExecutor
from prsm.compute.agents.compilers.hierarchical_compiler import HierarchicalCompiler
from prsm.compute.nwtn.orchestrator import NWTNOrchestrator


class AgentFrameworkTester:
    """Test the complete agent framework"""
    
    def __init__(self):
        self.agents = {}
        self.orchestrator = NWTNOrchestrator()
        self.test_session_id = uuid4()
    
    async def setup_agent_framework(self):
        """Set up the complete 5-layer agent framework"""
        print("ğŸ—ï¸ Setting up 5-layer agent framework...")
        
        # Create one agent of each type
        self.agents = {
            "architect": HierarchicalArchitect(level=1, max_depth=3),
            "router": ModelRouter(model_registry=self.orchestrator.model_registry),
            "executor": ModelExecutor(timeout_seconds=30),
            "compiler": HierarchicalCompiler(confidence_threshold=0.7)
        }
        
        # Register all agents
        for agent_type, agent in self.agents.items():
            agent_registry.register_agent(agent)
        
        # Set up some test models for routing
        await self._setup_test_models()
        
        print(f"âœ… Agent framework ready:")
        for agent_type, agent in self.agents.items():
            print(f"   - {agent_type.capitalize()}: {agent.agent_id[:8]}...")
    
    async def _setup_test_models(self):
        """Set up test models for agent routing"""
        from prsm.core.models import TeacherModel
        
        test_models = [
            {"name": "Research Specialist", "specialization": "research", "performance": 0.9},
            {"name": "Analysis Expert", "specialization": "data_analysis", "performance": 0.85},
            {"name": "General Assistant", "specialization": "general", "performance": 0.8}
        ]
        
        for model_data in test_models:
            model = TeacherModel(
                name=model_data["name"],
                specialization=model_data["specialization"],
                performance_score=model_data["performance"],
                curriculum_ids=[],
                student_models=[]
            )
            
            # Store in IPFS and register
            model_bytes = f"Model: {model_data['name']}".encode()
            cid = await self.orchestrator.ipfs_client.store_model(model_bytes, model_data)
            await self.orchestrator.model_registry.register_teacher_model(model, cid)
    
    async def test_individual_agents(self):
        """Test each agent type individually"""
        print("\nğŸ§ª Testing individual agents...")
        
        test_results = {}
        
        # Test Architect
        try:
            architect = self.agents["architect"]
            task_description = "Research the impact of AI on scientific discovery"
            
            response = await architect.safe_process(
                task_description, 
                {"session_id": self.test_session_id}
            )
            
            if response.success:
                hierarchy = response.output_data
                print(f"âœ… Architect: Created hierarchy with {hierarchy.total_tasks} tasks")
                test_results["architect"] = True
            else:
                print(f"âŒ Architect failed: {response.error_message}")
                test_results["architect"] = False
                
        except Exception as e:
            print(f"âŒ Architect error: {e}")
            test_results["architect"] = False
        
        # Test Router
        try:
            router = self.agents["router"]
            routing_request = {
                "task": "Analyze research data patterns",
                "complexity": 0.7
            }
            
            response = await router.safe_process(routing_request)
            
            if response.success:
                routing_decision = response.output_data
                # Extract candidates from RoutingDecision
                candidates = [routing_decision.primary_candidate] + routing_decision.backup_candidates
                print(f"âœ… Router: Found {len(candidates)} model candidates")
                test_results["router"] = True
            else:
                print(f"âŒ Router failed: {response.error_message}")
                test_results["router"] = False
                
        except Exception as e:
            print(f"âŒ Router error: {e}")
            test_results["router"] = False
        
        # Test Executor
        try:
            executor = self.agents["executor"]
            execution_request = {
                "task": "Explain quantum computing principles",
                "models": ["model_1", "model_2"],
                "parallel": True
            }
            
            response = await executor.safe_process(execution_request)
            
            if response.success:
                results = response.output_data
                successful = len([r for r in results if r.success])
                print(f"âœ… Executor: {successful}/{len(results)} executions successful")
                test_results["executor"] = True
            else:
                print(f"âŒ Executor failed: {response.error_message}")
                test_results["executor"] = False
                
        except Exception as e:
            print(f"âŒ Executor error: {e}")
            test_results["executor"] = False
        
        # Test Compiler
        try:
            compiler = self.agents["compiler"]
            
            # Create some mock execution results
            mock_results = [
                {
                    "type": "research_result",
                    "summary": "Quantum computing shows promise for scientific applications",
                    "confidence": 0.9
                },
                {
                    "type": "analysis_result", 
                    "summary": "Current limitations include decoherence and error rates",
                    "confidence": 0.85
                }
            ]
            
            response = await compiler.safe_process(
                mock_results,
                {"session_id": self.test_session_id, "strategy": "comprehensive"}
            )
            
            if response.success:
                result = response.output_data
                print(f"âœ… Compiler: Generated result with {result.confidence_score:.2f} confidence")
                test_results["compiler"] = True
            else:
                print(f"âŒ Compiler failed: {response.error_message}")
                test_results["compiler"] = False
                
        except Exception as e:
            print(f"âŒ Compiler error: {e}")
            test_results["compiler"] = False
        
        return test_results
    
    async def test_agent_coordination(self):
        """Test agents working together in coordination"""
        print("\nğŸ§ª Testing agent coordination...")
        
        try:
            # Step 1: Architect decomposes the task
            architect = self.agents["architect"]
            task = "Research and analyze data patterns in scientific literature"
            
            arch_response = await architect.safe_process(
                task, 
                {"session_id": self.test_session_id}
            )
            
            if not arch_response.success:
                print(f"âŒ Coordination failed at architect stage: {arch_response.error_message}")
                return False
            
            hierarchy = arch_response.output_data
            print(f"ğŸ“‹ Architect created {hierarchy.total_tasks} subtasks")
            
            # Step 2: Router finds models for each subtask
            router = self.agents["router"]
            routing_results = []
            
            # Route main task
            router_response = await router.safe_process({
                "task": task,
                "complexity": 0.8
            })
            
            if router_response.success:
                routing_decision = router_response.output_data
                # Extract candidates from RoutingDecision
                candidates = [routing_decision.primary_candidate] + routing_decision.backup_candidates
                print(f"ğŸ” Router found {len(candidates)} candidates for main task")
                routing_results.append(candidates)
            
            # Step 3: Executor runs tasks with selected models
            executor = self.agents["executor"]
            
            if routing_results and routing_results[0]:
                selected_models = [c.model_id for c in routing_results[0][:2]]  # Top 2 models
                
                exec_response = await executor.safe_process({
                    "task": task,
                    "models": selected_models,
                    "parallel": True
                })
                
                if not exec_response.success:
                    print(f"âŒ Coordination failed at executor stage: {exec_response.error_message}")
                    return False
                
                execution_results = exec_response.output_data
                successful_executions = [r for r in execution_results if r.success]
                print(f"âš¡ Executor completed {len(successful_executions)}/{len(execution_results)} tasks")
                
                # Step 4: Compiler synthesizes results
                compiler = self.agents["compiler"]
                
                comp_response = await compiler.safe_process(
                    execution_results,
                    {"session_id": self.test_session_id, "strategy": "comprehensive"}
                )
                
                if comp_response.success:
                    final_result = comp_response.output_data
                    print(f"ğŸ”„ Compiler generated final result:")
                    print(f"   - Confidence: {final_result.confidence_score:.2f}")
                    print(f"   - Compilation Level: {final_result.compilation_level}")
                    print(f"   - Reasoning Steps: {len(final_result.reasoning_trace)}")
                    return True
                else:
                    print(f"âŒ Coordination failed at compiler stage: {comp_response.error_message}")
                    return False
            else:
                print("âŒ No models available for execution")
                return False
                
        except Exception as e:
            print(f"âŒ Agent coordination error: {e}")
            return False
    
    async def test_safety_validation(self):
        """Test safety validation across agents"""
        print("\nğŸ§ª Testing safety validation...")
        
        unsafe_inputs = [
            "rm -rf / --no-preserve-root",  # Dangerous command
            "password: secret123",  # Potential credential
            "exec('malicious_code')",  # Code injection
        ]
        
        safe_rejections = 0
        total_tests = 0
        
        for agent_name, agent in self.agents.items():
            for unsafe_input in unsafe_inputs:
                try:
                    response = await agent.safe_process(unsafe_input)
                    total_tests += 1
                    
                    # In development mode, unsafe content is logged but not blocked
                    # Check if safety flags were created
                    if len(agent.safety_flags) > 0:
                        safe_rejections += 1
                        print(f"ğŸ›¡ï¸ {agent_name.capitalize()} detected safety concern: {unsafe_input[:30]}...")
                    
                except Exception as e:
                    total_tests += 1
                    safe_rejections += 1
                    print(f"ğŸ›¡ï¸ {agent_name.capitalize()} safely rejected: {unsafe_input[:30]}...")
        
        safety_rate = safe_rejections / total_tests if total_tests > 0 else 0
        print(f"ğŸ›¡ï¸ Safety validation: {safe_rejections}/{total_tests} concerns detected ({safety_rate:.1%})")
        
        return safety_rate > 0  # At least some safety concerns should be detected
    
    async def test_performance_tracking(self):
        """Test performance tracking across agents"""
        print("\nğŸ§ª Testing performance tracking...")
        
        total_operations = 0
        agents_with_metrics = 0
        
        for agent_name, agent in self.agents.items():
            stats = agent.performance_tracker.get_performance_stats()
            total_operations += stats.get("total_operations", 0)
            
            if stats.get("total_operations", 0) > 0:
                agents_with_metrics += 1
                print(f"ğŸ“Š {agent_name.capitalize()}: {stats['total_operations']} ops, "
                      f"{stats.get('success_rate', 0):.1%} success rate")
        
        print(f"ğŸ“Š Performance tracking: {total_operations} total operations across {agents_with_metrics} agents")
        
        # Test global agent registry
        system_status = agent_registry.get_system_status()
        print(f"ğŸŒ System status: {system_status['total_agents']} agents, "
              f"{system_status['active_agents']} active")
        
        return agents_with_metrics == len(self.agents)
    
    async def test_agent_pools(self):
        """Test agent pool functionality"""
        print("\nğŸ§ª Testing agent pools...")
        
        pool_tests_passed = 0
        total_pool_tests = 0
        
        for agent_type in [AgentType.ARCHITECT, AgentType.ROUTER, AgentType.EXECUTOR, AgentType.COMPILER]:
            total_pool_tests += 1
            
            pool = agent_registry.get_pool(agent_type)
            if pool:
                status = pool.get_pool_status()
                print(f"ğŸŠ {agent_type.value} pool: {status['total_agents']} total, "
                      f"{status['active_agents']} active")
                
                # Test pool processing
                try:
                    response = await pool.process_with_pool("Test task for pool")
                    if response.success:
                        pool_tests_passed += 1
                        print(f"âœ… {agent_type.value} pool processing successful")
                    else:
                        print(f"âŒ {agent_type.value} pool processing failed")
                except Exception as e:
                    print(f"âŒ {agent_type.value} pool error: {e}")
            else:
                print(f"âŒ No pool found for {agent_type.value}")
        
        pool_success_rate = pool_tests_passed / total_pool_tests if total_pool_tests > 0 else 0
        return pool_success_rate >= 0.75  # At least 75% of pools should work
    
    async def run_all_tests(self):
        """Run all agent framework tests"""
        print("ğŸš€ Agent Framework Integration Testing")
        print("Testing Phase 1 / Week 4 - Agent Foundation Layer")
        print("=" * 60)
        
        await self.setup_agent_framework()
        
        tests = [
            ("Individual Agent Testing", self.test_individual_agents),
            ("Agent Coordination", self.test_agent_coordination),
            ("Safety Validation", self.test_safety_validation),
            ("Performance Tracking", self.test_performance_tracking),
            ("Agent Pools", self.test_agent_pools)
        ]
        
        results = []
        
        for test_name, test_func in tests:
            try:
                result = await test_func()
                
                # Handle different return types
                if isinstance(result, dict):
                    # Individual agent tests return dict
                    success = all(result.values())
                    print(f"\nğŸ“Š {test_name} Results:")
                    for agent_type, passed in result.items():
                        status = "âœ…" if passed else "âŒ"
                        print(f"   {status} {agent_type.capitalize()}")
                else:
                    # Other tests return boolean
                    success = bool(result)
                
                results.append((test_name, success))
                
            except Exception as e:
                print(f"âŒ {test_name} crashed: {e}")
                results.append((test_name, False))
        
        # Print summary
        print("\n" + "=" * 60)
        print("ğŸ“Š AGENT FRAMEWORK TEST SUMMARY")
        print("=" * 60)
        
        passed = sum(1 for _, result in results if result)
        total = len(results)
        
        for test_name, result in results:
            status = "âœ…" if result else "âŒ"
            print(f"{status} {test_name}")
        
        print(f"\nğŸ“ˆ Results: {passed}/{total} test suites passed")
        
        if passed == total:
            print("ğŸ‰ ALL AGENT FRAMEWORK TESTS PASSED!")
            print("âœ… 5-layer agent system is fully operational:")
            print("   - BaseAgent framework with safety & performance âœ“")
            print("   - HierarchicalArchitect with recursive decomposition âœ“")
            print("   - ModelRouter with intelligent model selection âœ“")
            print("   - ModelExecutor with parallel execution âœ“")
            print("   - HierarchicalCompiler with multi-stage synthesis âœ“")
            print("   - Agent pools and global registry âœ“")
            print("   - NWTN orchestrator integration ready âœ“")
        else:
            print(f"âš ï¸  {total - passed} test suites failed. Review and fix issues.")
        
        return passed == total


async def main():
    """Run agent framework tests"""
    tester = AgentFrameworkTester()
    success = await tester.run_all_tests()
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())